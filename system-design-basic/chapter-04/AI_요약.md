### 주요 주제
- 분산 환경에서 레이트 리미터 구현 방법과 상용 API 게이트웨이 사용 여부
- 토픽 메시지에 쌓고 끝이라 컨슈머가 있는 전략
- 토스의 오픈 API 제공 시 지연 문제 해결 방법


### 다음 할 일
- 처리율 제한 장치 구현 방법 검토
- 버킷 포제이를 활용한 분산 트랜잭션 구현 방법 검토
- 레디스 오퍼레이션에 멀티 카운트 설정 및 원자성 보장 방법 검토


---

### 서버의 동시성 이슈
- 트래픽 양이 예상이 되면 미리 스케일아웃 해서 얼마나 해놓으면 받아들일 수 있을지 테스트 사전에 돌려보고 능동적으로 대응하면 될 것 같음
- 이벤트라고 해서 저는 약간 뭔가 그쪽으로 생각을 했음
- 예를 들어서 선착순 이벤트면은 동시성 이슈 없이 순번 챙기는 게 더 중요함
- 서버 여러 대 있으면 요청 타임 스탬프 상으로는 예를 들어서 a가 더 빨리 했는데 요청은 b가 더 빨리 도착해가지고 b가 먼저 처리될 수도 있음


### 처리율 제한 장치
- 처리율 제한 장치라는 말을 들었을 때 DB 쪽에서도 처리율을 제한시키는 장치도 있나 생각을 처음 하면서 봄
- 디도스는 다수의 분산 환경에 있는 좀비 PC나 봇들에 의한 대규모 공격을 디도스라고 부름
- 처리율 제한 장치를 한 대라고 하면 백엔드 애플리케이션 안에서 간단하게 구현해도 되는지 분리를 해야 되는지 생각을 여쭤보려고 함
- 처리율 제한도 만약에 완벽하게 안 지켜도 되면 훨씬 더 성능적으로 좋은 설계가 나을 수 있겠다 방법은 여러 개겠지만 러프하게 잡고 지나가고 있음

### API 게이트웨이의 개념
- API 게이트웨이를 사용하고 있는지 상용 API 게이트를 쓰는지 본인들이 직접 만든 스프링 클라우드 게이트웨이 같은 걸 쓰는지에 대한 질문이었음
- API 게이트웨이를 사용하고 있었으니까 처리율 제한 장치에 장치 미들웨어 같은 느낌으로 대신 쓸 수 있음

### 분산 트랜잭션의 구현 방법
- 분산 트랜잭션을 구현하는 방법은 오케스트레이터가 있는 방식과 없는 방식이 있음
- 오케스트레이터가 있으면 트랜잭션의 처리 과정을 기록하기 쉽고 확인하기 쉬움
- 오케스트레이터가 있어야 된다는 자체가 단점임

### AWS API Gateway 디폴트 값
- 디폴트 값이 있어서 콘솔에서 변경을 할 수 있음
- 원인을 찾아내는 데 며칠이 걸렸는데 의심 가는 데가 너무 많았음
- 기본적인 환경에서 테스트를 하다 보니까 클라이언트도 고부하가 생겼을 때 고정 IP에서 올 수가 없음
- 실제 같은 환경을 만들면 더 괜찮았을 것 같음

### 선착순 이벤트 설계
- 선착순 이벤트를 설계하라는 내용이 있었음
- 데이터를 어떻게 정확하게 선착순 데이터를 관리를 할 거냐로 시작을 했었음
- 동시성 이슈를 어떻게 잡냐 해서 비관 정답을 걸면 되지 않을까요?라고 함

### CAS 알고리즘의 성능
- CAS 알고리즘을 키워드에 대해서 끝나고 공부해 보라고 함
- 레디스의 워치 명령을 쓰면 키 값이 변경되는 것을 감지해 줌
- 동시성이 굉장히 높은 상황에서는 CAS 알고리즘도 성능이 많이 떨어짐
- 루아 스크립트를 쓰면 원자력 변전이 보장이 됨
- 동시성이 높아질수록 CAS 알고리즘도 성능이 안 좋아짐
- 스케일 아웃 되는 것도 생각을 해야 함

### Bucket4j
- 버킷 포제는 버킷 관리하는 버킷 내에 토큰이 있고 처리 시마다 토큰 사용됨
- 기본적으로는 다 인메모리로 동작함
- 분산 환경에서 쓸 거면은 버킷 포제이를 찾아보라고 함

### 분산 환경에서 레이트 리미터 구현
- 분산 환경에서 레이트 리미터를 구현하려면은 인크리먼트 카운터 증가시키는 인크리지 커맨드는 적절하지 않음
- 분산 환경에서 레이트 리미터를 구현하려면은 루아 스크립트를 많이 사용함
- 상용을 사용하고자 하는 계획은 없었는지 묻자 API 게이트웨이를 썼다고 함

### 원자성
- 조회부터 잉크리먼트까지를 라스크립트 하나로 처리하는 것은 원자성이 깨진 것 같음
- 루아 스크립트로 작성해서 조회 먼저 다 해놓고 조회부터 실행시키고 루아 스크립트를 많이 씀

### 토스의 스케줄링 서버
- 토스는 오픈 API 같은 거 제공할 때 지연을 레이트 리미트를 안 하고 본인 서버에 q에 뭔가 쌓아서 처리함
- 스케줄링 서버가 따로 있어서 이벤트 꺼내서 쓰다가 실패하면 스케줄링 서버에 넣어가지고 나중에 회복시키고 자동화되어 있음
- 카프카 UI로 하고 있는데 카프카에 쌓인 토픽을 가지고 다른 토픽으로 스트림을 만들어 가지고 메시지를 넣어가지고 타겟 토픽으로 날림